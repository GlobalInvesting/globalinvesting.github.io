name: Update Extended Data (Bonds + Sentiment + Flows + rateMomentum) - v7

on:
  schedule:
    - cron: '30 6 * * *'
  workflow_dispatch:

jobs:
  update-extended-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests beautifulsoup4 lxml --break-system-packages

      - name: Create directory
        run: mkdir -p extended-data

      - name: Scrape extended indicators
        run: |
          python3 << 'EOFPYTHON'
          import requests
          from bs4 import BeautifulSoup
          import json, re, os, time
          from datetime import date, datetime

          HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          }

          CURRENCIES = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']

          COUNTRY_NAMES = {
              'USD': ['United States'],
              'EUR': ['Euro Area'],
              'GBP': ['United Kingdom'],
              'JPY': ['Japan'],
              'CAD': ['Canada'],
              'AUD': ['Australia'],
              'CHF': ['Switzerland'],
              'NZD': ['New Zealand']
          }

          TE_URLS = {
              'bond10y':               'https://tradingeconomics.com/country-list/government-bond-yield?continent=world',
              'consumerConfidence':    'https://tradingeconomics.com/country-list/consumer-confidence?continent=world',
              'businessConfidence':    'https://tradingeconomics.com/country-list/business-confidence?continent=world',
              'capitalFlows':          'https://tradingeconomics.com/country-list/capital-flows?continent=world',
              'fdi':                   'https://tradingeconomics.com/country-list/foreign-direct-investment?continent=world',
              'inflationExpectations': 'https://tradingeconomics.com/country-list/inflation-expectations?continent=world',
          }

          # â”€â”€ v6: EUR bond10y uses the dedicated TE /bonds page (GEUGB10Y:GOV) â”€â”€â”€â”€
          BONDS_MARKET_PAGE = 'https://tradingeconomics.com/bonds'

          # â”€â”€ v7 NEW: Interest rate history pages for rateMomentum calculation â”€â”€â”€â”€
          # rateMomentum = current_rate - rate_12_months_ago
          # Positive = BC raising rates (hawkish momentum), negative = cutting (dovish momentum)
          RATE_HISTORY_URLS = {
              'USD': 'https://tradingeconomics.com/united-states/interest-rate',
              'EUR': 'https://tradingeconomics.com/euro-area/interest-rate',
              'GBP': 'https://tradingeconomics.com/united-kingdom/interest-rate',
              'JPY': 'https://tradingeconomics.com/japan/interest-rate',
              'CAD': 'https://tradingeconomics.com/canada/interest-rate',
              'AUD': 'https://tradingeconomics.com/australia/interest-rate',
              'CHF': 'https://tradingeconomics.com/switzerland/interest-rate',
              'NZD': 'https://tradingeconomics.com/new-zealand/interest-rate',
          }

          # â”€â”€ country-list interest rate page (has "1Y ago" column) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          RATE_LIST_URL = 'https://tradingeconomics.com/country-list/interest-rate?continent=world'

          # â”€â”€ FX RATES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          exchange_rates = {}

          def fetch_fx():
              global exchange_rates
              try:
                  r = requests.get('https://api.frankfurter.app/latest?from=USD', timeout=10)
                  if r.ok:
                      exchange_rates = r.json().get('rates', {})
                      exchange_rates['USD'] = 1.0
                      print(f"  âœ… FX rates loaded: {sorted(exchange_rates.keys())}")
                      return True
              except Exception as e:
                  print(f"  âš ï¸ FX fetch failed: {e}")
              exchange_rates = {
                  'USD': 1.0, 'EUR': 0.92, 'GBP': 0.79, 'JPY': 150.0,
                  'CAD': 1.36, 'AUD': 1.57, 'CHF': 0.90, 'NZD': 1.67,
              }
              print("  âš ï¸ Using fallback FX rates")
              return False

          # â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def clean_num(text):
              if not text: return None
              text = str(text).strip().replace(',','').replace('%','')
              m = re.search(r'(-?\d+\.?\d*)', text)
              return float(m.group(1)) if m else None

          def parse_te_date(date_text):
              if not date_text: return str(date.today())
              date_text = date_text.strip()
              try:
                  m = re.match(r'^([A-Za-z]{3})/(\d{2})$', date_text)
                  if m:
                      dt = datetime.strptime(f"{m.group(1)} 20{m.group(2)}", '%b %Y')
                      return dt.strftime('%Y-%m-15')
                  m = re.match(r'^([A-Za-z]{3})\s+(\d{4})$', date_text)
                  if m:
                      dt = datetime.strptime(f"{m.group(1)} {m.group(2)}", '%b %Y')
                      return dt.strftime('%Y-%m-15')
                  m = re.search(r'Q(\d)[/\s](\d{4})', date_text)
                  if m:
                      month = (int(m.group(1)) - 1) * 3 + 2
                      return f"{m.group(2)}-{month:02d}-15"
              except: pass
              return str(date.today())

          # â”€â”€ v7 NEW: rateMomentum scraping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def scrape_rate_momentum():
              """
              Scrape rateMomentum = current_rate - rate_12_months_ago for all currencies.

              Strategy 1 (preferred):
                TE country-list/interest-rate page has columns:
                Country | Last | Previous | Reference | Unit | 1Y ago | ...
                The "1Y ago" column gives us the rate 12 months ago directly.

              Strategy 2 (fallback per-currency):
                Individual country interest-rate pages sometimes show a table with
                historical values. We look for a row dated ~12 months ago.

              Strategy 3 (fallback):
                GitHub Pages rates/<CURR>.json already stores the current rate.
                If we can identify the rate 1Y ago from an API, use that.
              """
              print(f"\n{'='*50}\nRATE MOMENTUM (v7 â€” current minus 12M ago)\n{'='*50}")
              momentum = {}
              momentum_dates = {}

              # â”€â”€ Strategy 1: country-list page with "1Y ago" column â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              try:
                  r = requests.get(RATE_LIST_URL, headers=HEADERS, timeout=20)
                  if r.status_code == 429:
                      print("  âš ï¸ Rate limited on rate-list, waiting 30s...")
                      time.sleep(30)
                      r = requests.get(RATE_LIST_URL, headers=HEADERS, timeout=20)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')

                  table = soup.find('table', {'class': 'table'})
                  if table:
                      headers_row = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                      print(f"  Table headers: {headers_row}")

                      # Find "last" / "actual" column (current rate)
                      last_idx = None
                      for label in ['actual', 'last']:
                          if label in headers_row:
                              last_idx = headers_row.index(label)
                              break

                      # Find "1Y ago" column â€” TE labels it variously
                      year_ago_idx = None
                      for label in ['1y ago', '1 y ago', '1 year ago', '12m ago', 'year ago', '1y']:
                          if label in headers_row:
                              year_ago_idx = headers_row.index(label)
                              break

                      # Also check for "change 1y" which is (current - 1y_ago)
                      change_1y_idx = None
                      for label in ['change 1y', '1y change', 'chg 1y', 'annual change']:
                          if label in headers_row:
                              change_1y_idx = headers_row.index(label)
                              break

                      if last_idx is None:
                          print("  âš ï¸ Could not find 'last/actual' column in rate list")
                      else:
                          print(f"  Column indices â€” last: {last_idx}, 1y_ago: {year_ago_idx}, change_1y: {change_1y_idx}")

                          for row in table.find_all('tr')[1:]:
                              cols = row.find_all('td')
                              if len(cols) < 2: continue
                              ctry = cols[0].get_text(strip=True)

                              for code, names in COUNTRY_NAMES.items():
                                  if code in momentum: continue
                                  if any(n.lower() in ctry.lower() for n in names):
                                      current_rate = clean_num(cols[last_idx].get_text(strip=True)) if last_idx and len(cols) > last_idx else None

                                      if current_rate is None: break

                                      # Path A: direct 1Y ago column
                                      if year_ago_idx and len(cols) > year_ago_idx:
                                          rate_1y = clean_num(cols[year_ago_idx].get_text(strip=True))
                                          if rate_1y is not None:
                                              m_val = round(current_rate - rate_1y, 4)
                                              momentum[code] = m_val
                                              momentum_dates[code] = str(date.today())
                                              print(f"  âœ“ {code}: current={current_rate}% | 1y_ago={rate_1y}% | momentum={m_val:+.3f}% [col]")
                                              break

                                      # Path B: 1Y change column â†’ momentum = change directly
                                      if change_1y_idx and len(cols) > change_1y_idx:
                                          change = clean_num(cols[change_1y_idx].get_text(strip=True))
                                          if change is not None:
                                              momentum[code] = round(change, 4)
                                              momentum_dates[code] = str(date.today())
                                              print(f"  âœ“ {code}: current={current_rate}% | 1y_change={change:+.3f}% [delta col]")
                                              break

                                      print(f"  âš ï¸ {code}: current={current_rate}% but no 1Y data in table")
                                      break

              except Exception as e:
                  print(f"  âŒ Rate list page error: {e}")

              # â”€â”€ Strategy 2: Individual country pages for missing currencies â”€â”€â”€â”€â”€â”€â”€â”€
              missing = [c for c in CURRENCIES if c not in momentum]
              if missing:
                  print(f"\n  Individual page fallback for: {', '.join(missing)}")
                  for code in missing:
                      url = RATE_HISTORY_URLS[code]
                      try:
                          r = requests.get(url, headers=HEADERS, timeout=15)
                          r.raise_for_status()
                          soup = BeautifulSoup(r.content, 'lxml')

                          # Look for "Previous Rate" or history table
                          # TE individual pages often have a small stats box:
                          # Current | Previous | Highest | Lowest | Unit | Reference
                          # We scan for any table with historical rate data

                          # Method A: stats box (div with class 'te-stats-box' or similar)
                          found = False

                          # Method B: any table containing rate-like values
                          for table in soup.find_all('table'):
                              headers_row = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                              # Look for "1 year ago" or similar
                              for label in ['1 year ago', '1y ago', 'year ago', '12m ago']:
                                  if label in headers_row:
                                      idx = headers_row.index(label)
                                      for row in table.find_all('tr')[1:]:
                                          cols = row.find_all('td')
                                          if len(cols) > max(1, idx):
                                              current = clean_num(cols[1].get_text(strip=True)) if len(cols) > 1 else None
                                              old_val = clean_num(cols[idx].get_text(strip=True)) if len(cols) > idx else None
                                              if current is not None and old_val is not None and 0 <= current <= 25 and 0 <= old_val <= 25:
                                                  m_val = round(current - old_val, 4)
                                                  momentum[code] = m_val
                                                  momentum_dates[code] = str(date.today())
                                                  print(f"  âœ“ {code}: {current}% - {old_val}% = {m_val:+.3f}% [country page]")
                                                  found = True
                                                  break
                                          if found: break
                                      if found: break
                                  if found: break

                          if not found:
                              # Method C: scrape the JSON-LD or meta data for current vs previous
                              # TE pages include <script type="application/ld+json"> with rate data
                              for script in soup.find_all('script', type='application/ld+json'):
                                  try:
                                      ld = json.loads(script.string or '{}')
                                      # Sometimes has currentValue and previousValue
                                      current = None
                                      previous = None
                                      if isinstance(ld, dict):
                                          current  = ld.get('currentValue') or ld.get('value')
                                          previous = ld.get('previousValue')
                                          if current and previous:
                                              c = clean_num(str(current))
                                              p = clean_num(str(previous))
                                              # "Previous" on TE is usually previous meeting, not 1Y ago
                                              # We can't reliably use this for 12M momentum â†’ skip
                                  except: pass

                              print(f"  âš ï¸ {code}: No 1Y rate found on country page â†’ momentum=null")

                      except Exception as e:
                          print(f"  âŒ {code} country page: {e}")
                      time.sleep(1)

              # â”€â”€ Strategy 3: GitHub Pages historical rates JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              # Our rates/<CURR>.json stores observations array with date+value.
              # If it has enough history (12+ months), compute from oldest entry.
              still_missing = [c for c in CURRENCIES if c not in momentum]
              if still_missing:
                  print(f"\n  GitHub rates fallback for: {', '.join(still_missing)}")
                  for code in still_missing:
                      try:
                          url = f'https://globalinvesting.github.io/rates/{code}.json'
                          r = requests.get(url, timeout=10)
                          if r.ok:
                              data = r.json()
                              obs = data.get('observations', [])
                              if len(obs) >= 2:
                                  # obs[0] = most recent, find one ~12 months ago
                                  current_val = clean_num(str(obs[0].get('value', '')))
                                  current_date = obs[0].get('date', '')

                                  target_dt = None
                                  if current_date:
                                      try:
                                          cd = datetime.strptime(current_date, '%Y-%m-%d')
                                          target_dt = cd.replace(year=cd.year - 1)
                                      except: pass

                                  closest_val = None
                                  closest_diff = float('inf')
                                  for ob in obs[1:]:
                                      ob_dt_str = ob.get('date', '')
                                      ob_val = clean_num(str(ob.get('value', '')))
                                      if ob_val is None or ob_val == '.': continue
                                      if target_dt and ob_dt_str:
                                          try:
                                              od = datetime.strptime(ob_dt_str, '%Y-%m-%d')
                                              diff = abs((od - target_dt).days)
                                              if diff < closest_diff:
                                                  closest_diff = diff
                                                  closest_val = ob_val
                                          except: pass

                                  if current_val is not None and closest_val is not None and closest_diff < 90:
                                      m_val = round(current_val - closest_val, 4)
                                      momentum[code] = m_val
                                      momentum_dates[code] = str(date.today())
                                      print(f"  âœ“ {code}: {current_val}% - {closest_val}% = {m_val:+.3f}% [GH rates, {closest_diff}d off target]")
                                  else:
                                      print(f"  âš ï¸ {code}: GitHub rates insufficient history (obs={len(obs)}, closest_diff={closest_diff}d)")
                      except Exception as e:
                          print(f"  âš ï¸ {code} GitHub rates fallback: {e}")

              final_missing = [c for c in CURRENCIES if c not in momentum]
              if final_missing:
                  print(f"\n  âŒ rateMomentum unavailable for: {', '.join(final_missing)} (will be null)")
              else:
                  print(f"\n  âœ… rateMomentum complete for all currencies")

              return momentum, momentum_dates

          # â”€â”€ CAPITAL FLOWS: Unit-aware FX conversion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def parse_capital_flows_row(cols):
              if len(cols) < 5:
                  return None
              raw_val  = clean_num(cols[1].get_text(strip=True))
              unit_str = cols[4].get_text(strip=True)
              if raw_val is None or not unit_str:
                  return None
              unit_upper = unit_str.upper()
              if 'TRILLION' in unit_upper:
                  scale = 1_000_000.0
              elif 'BILLION' in unit_upper:
                  scale = 1_000.0
              elif 'HUNDRED MILLION' in unit_upper:
                  scale = 100.0
              elif 'MILLION' in unit_upper:
                  scale = 1.0
              else:
                  print(f"    âš ï¸ Unknown scale in unit '{unit_str}' â€” treating as millions")
                  scale = 1.0
              m = re.match(r'^([A-Z]{3})\b', unit_upper)
              src_currency = m.group(1) if m else 'USD'
              val_native_millions = raw_val * scale
              if src_currency == 'USD':
                  val_usd_millions = val_native_millions
              else:
                  fx = exchange_rates.get(src_currency)
                  if fx and fx > 0:
                      val_usd_millions = val_native_millions / fx
                  else:
                      print(f"    âš ï¸ No FX rate for {src_currency} â€” skipping")
                      return None
              return round(val_usd_millions, 2)

          # â”€â”€ CONFIDENCE NORMALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def normalize_confidence(value, currency, indicator):
              if value is None:
                  return None
              if indicator == 'consumerConfidence':
                  if currency in ('EUR', 'GBP'):
                      return round(value + 100, 2)
                  if currency == 'JPY':
                      return round(((value - 40) / 10) * 15 + 100, 2)
                  if currency == 'CHF':
                      return round(value + 130, 2)
                  return value
              if indicator == 'businessConfidence':
                  if currency in ('EUR', 'GBP', 'JPY', 'AUD'):
                      return round(value + 100, 2)
                  if currency == 'NZD':
                      return round(value, 2)
                  return value
              return value

          # â”€â”€ GENERIC TABLE SCRAPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def scrape_te_table(url, label):
              print(f"\n{'='*50}\nSCRAPING: {label}\n{'='*50}")
              data, dates = {}, {}
              try:
                  r = requests.get(url, headers=HEADERS, timeout=20)
                  if r.status_code == 429:
                      print(f"  âš ï¸ Rate limited, waiting 30s...")
                      time.sleep(30)
                      r = requests.get(url, headers=HEADERS, timeout=20)
                  r.raise_for_status()

                  soup = BeautifulSoup(r.content, 'lxml')
                  table = soup.find('table', {'class': 'table'})
                  if not table:
                      print("  âŒ No table found"); return data, dates

                  headers_row = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                  if 'actual' in headers_row:
                      actual_idx = headers_row.index('actual')
                  elif 'last' in headers_row:
                      actual_idx = headers_row.index('last')
                  else:
                      actual_idx = 1
                  date_idx = headers_row.index('reference') if 'reference' in headers_row else None

                  for row in table.find_all('tr')[1:]:
                      cols = row.find_all('td')
                      if len(cols) < 2: continue
                      ctry = cols[0].get_text(strip=True)
                      for code, names in COUNTRY_NAMES.items():
                          if any(n.lower() in ctry.lower() for n in names):
                              dt = parse_te_date(cols[date_idx].get_text(strip=True)) if date_idx and len(cols) > date_idx else str(date.today())

                              if label == 'capitalFlows':
                                  val_usd = parse_capital_flows_row(cols)
                                  if val_usd is not None:
                                      unit_str = cols[4].get_text(strip=True) if len(cols) > 4 else 'N/A'
                                      raw_str  = cols[1].get_text(strip=True)
                                      print(f"  âœ“ {code}: {raw_str} {unit_str} â†’ {val_usd:.1f} USD M ({dt})")
                                      data[code]  = val_usd
                                      dates[code] = dt

                              elif label in ('consumerConfidence', 'businessConfidence'):
                                  raw_val = clean_num(cols[actual_idx].get_text(strip=True))
                                  if raw_val is not None:
                                      normalized = normalize_confidence(raw_val, code, label)
                                      print(f"  âœ“ {code}: raw={raw_val} â†’ normalized={normalized} ({dt})")
                                      data[code]  = round(normalized, 4) if normalized is not None else None
                                      dates[code] = dt

                              else:
                                  raw_val = clean_num(cols[actual_idx].get_text(strip=True))
                                  if raw_val is not None:
                                      data[code]  = round(raw_val, 4)
                                      dates[code] = dt
                                      print(f"  âœ“ {code}: {raw_val} ({dt})")
                              break

              except Exception as e:
                  print(f"  âŒ {e}")
              return data, dates

          # â”€â”€ BOND YIELDS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          BOND_COUNTRY_MAP = {
              'USD': ['United States'],
              'EUR': ['Euro area'],
              'GBP': ['United Kingdom'],
              'JPY': ['Japan'],
              'CAD': ['Canada'],
              'AUD': ['Australia'],
              'CHF': ['Switzerland'],
              'NZD': ['New Zealand'],
          }
          BOND_COUNTRY_SLUGS = {
              'USD': 'united-states',
              'EUR': 'euro-area',
              'GBP': 'united-kingdom',
              'JPY': 'japan',
              'CAD': 'canada',
              'AUD': 'australia',
              'CHF': 'switzerland',
              'NZD': 'new-zealand',
          }
          BOND_EXPECTED_RANGES = {
              'USD': (3.0, 6.0),
              'EUR': (2.0, 4.5),
              'GBP': (3.5, 5.5),
              'JPY': (0.5, 3.5),
              'CAD': (2.5, 5.0),
              'AUD': (3.5, 6.0),
              'CHF': (0.0, 2.0),
              'NZD': (3.5, 6.0),
          }

          def _fetch_eur_bond_from_market_page():
              print(f"\n  â†’ Fetching EUR bond from TE /bonds market page...")
              try:
                  r = requests.get(BONDS_MARKET_PAGE, headers=HEADERS, timeout=20)
                  if r.status_code == 429:
                      print("  âš ï¸ Rate limited on /bonds, waiting 30s...")
                      time.sleep(30)
                      r = requests.get(BONDS_MARKET_PAGE, headers=HEADERS, timeout=20)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')

                  ea_row = soup.find('tr', {'data-symbol': 'GEUGB10Y:GOV'})
                  if ea_row:
                      price_td = ea_row.find('td', {'id': 'p'})
                      date_td  = ea_row.find('td', {'id': 'date'})
                      if price_td:
                          val = clean_num(price_td.get_text(strip=True))
                          dt  = str(date.today())
                          if date_td:
                              dt = parse_te_date(date_td.get_text(strip=True))
                          if val is not None and 2.0 <= val <= 4.5:
                              print(f"  âœ“ EUR [/bonds EA GEUGB10Y]: {val}% ({dt})")
                              return round(val, 3), dt

                  for row in soup.find_all('tr'):
                      cells = row.find_all('td')
                      if len(cells) < 3: continue
                      for i, cell in enumerate(cells):
                          if 'euro area' in cell.get_text(strip=True).lower():
                              for price_cell in cells[i+1:]:
                                  val = clean_num(price_cell.get_text(strip=True))
                                  if val is not None and 2.0 <= val <= 4.5:
                                      print(f"  âœ“ EUR [/bonds text search]: {val}%")
                                      return round(val, 3), str(date.today())
                              break

              except Exception as e:
                  print(f"  âœ— EUR /bonds market page: {e}")
              return None, None

          def _extract_bonds_from_all_tables(soup):
              data, dates = {}, {}
              for table in soup.find_all('table'):
                  for row in table.find_all('tr'):
                      cols = row.find_all('td')
                      if len(cols) < 2: continue
                      ctry_text = cols[0].get_text(strip=True)
                      for code, names in BOND_COUNTRY_MAP.items():
                          if code in data: continue
                          if any(n.lower() in ctry_text.lower() for n in names):
                              for idx in [1, 2, 3]:
                                  if idx >= len(cols): continue
                                  val = clean_num(cols[idx].get_text(strip=True))
                                  if val is not None and 0 < val < 20:
                                      data[code]  = round(val, 3)
                                      dates[code] = str(date.today())
                                      print(f"  âœ“ {code}: {val}% (widget table)")
                                      break
              return data, dates

          def _bond_country_page_fallback(code):
              slug = BOND_COUNTRY_SLUGS.get(code)
              if not slug: return None, None
              min_val, max_val = BOND_EXPECTED_RANGES.get(code, (0.5, 10.0))
              url = f'https://tradingeconomics.com/{slug}/government-bond-yield'
              try:
                  r = requests.get(url, headers=HEADERS, timeout=15)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')
                  for table in soup.find_all('table'):
                      for row in table.find_all('tr'):
                          cols = row.find_all('td')
                          for col in cols:
                              val = clean_num(col.get_text(strip=True))
                              if val is not None and min_val <= val <= max_val:
                                  print(f"  âœ“ {code}: {val}% (country page fallback)")
                                  return round(val, 3), str(date.today())
              except Exception as e:
                  print(f"  âŒ Country page fallback {code}: {e}")
              return None, None

          def scrape_bonds():
              print(f"\n{'='*50}\nBOND YIELDS (v6 â€” EUR via /bonds market page)\n{'='*50}")
              data, dates = {}, {}

              eur_val, eur_dt = _fetch_eur_bond_from_market_page()
              if eur_val is not None:
                  data['EUR']  = eur_val
                  dates['EUR'] = eur_dt
              time.sleep(1)

              try:
                  r = requests.get(TE_URLS['bond10y'], headers=HEADERS, timeout=20)
                  if r.status_code == 429:
                      print("  âš ï¸ Rate limited, waiting 30s...")
                      time.sleep(30)
                      r = requests.get(TE_URLS['bond10y'], headers=HEADERS, timeout=20)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')

                  std_table = soup.find('table', {'class': 'table'})
                  if std_table:
                      headers_row = [h.get_text(strip=True).lower() for h in std_table.find_all('th')]
                      actual_idx = headers_row.index('actual') if 'actual' in headers_row else 1
                      if actual_idx == 1 and 'last' in headers_row:
                          actual_idx = headers_row.index('last')
                      date_idx = headers_row.index('reference') if 'reference' in headers_row else None
                      for row in std_table.find_all('tr')[1:]:
                          cols = row.find_all('td')
                          if len(cols) < 2: continue
                          ctry = cols[0].get_text(strip=True)
                          for code, names in BOND_COUNTRY_MAP.items():
                              if code == 'EUR': continue
                              if any(n.lower() in ctry.lower() for n in names):
                                  val = clean_num(cols[actual_idx].get_text(strip=True))
                                  dt  = parse_te_date(cols[date_idx].get_text(strip=True)) if date_idx and len(cols) > date_idx else str(date.today())
                                  min_v, max_v = BOND_EXPECTED_RANGES.get(code, (0, 20))
                                  if val is not None and min_v <= val <= max_v:
                                      data[code] = round(val, 3)
                                      dates[code] = dt
                                      print(f"  âœ“ {code}: {val}% ({dt})")
                                  break

                  missing_non_eur = [c for c in CURRENCIES if c != 'EUR' and c not in data]
                  if missing_non_eur:
                      print(f"  Scanning all tables for: {', '.join(missing_non_eur)}")
                      w_data, w_dates = _extract_bonds_from_all_tables(soup)
                      for code in missing_non_eur:
                          if code in w_data:
                              min_v, max_v = BOND_EXPECTED_RANGES.get(code, (0, 20))
                              if min_v <= w_data[code] <= max_v:
                                  data[code]  = w_data[code]
                                  dates[code] = w_dates[code]
                              else:
                                  print(f"  âš ï¸ {code}: {w_data[code]}% out of range â†’ discarded")

              except Exception as e:
                  print(f"  âŒ TE bond country-list page error: {e}")

              still_missing = [c for c in CURRENCIES if c not in data]
              if still_missing:
                  print(f"\n  Country-page fallback for: {', '.join(still_missing)}")
                  for code in still_missing:
                      val, dt = _bond_country_page_fallback(code)
                      if val is not None:
                          data[code]  = val
                          dates[code] = dt
                      time.sleep(1)

              print(f"\n  Found:   {[c for c in CURRENCIES if c in data]}")
              print(f"  Missing: {[c for c in CURRENCIES if c not in data]}")
              return data, dates

          # â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          print(f"\n{'='*50}\nFETCHING FX RATES\n{'='*50}")
          fetch_fx()

          all_data  = {c: {} for c in CURRENCIES}
          all_dates = {c: {} for c in CURRENCIES}

          bond_data, bond_dates = scrape_bonds()
          for c in CURRENCIES:
              all_data[c]['bond10y']  = bond_data.get(c)
              all_dates[c]['bond10y'] = bond_dates.get(c, str(date.today()))
          time.sleep(2)

          for key, url in {k: v for k, v in TE_URLS.items() if k != 'bond10y'}.items():
              d, dt = scrape_te_table(url, key)
              for c in CURRENCIES:
                  all_data[c][key]  = d.get(c)
                  all_dates[c][key] = dt.get(c, str(date.today()))
              time.sleep(2)

          # â”€â”€ v7 NEW: rateMomentum â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          rate_momentum, rate_momentum_dates = scrape_rate_momentum()
          for c in CURRENCIES:
              all_data[c]['rateMomentum']  = rate_momentum.get(c)  # null if unavailable
              all_dates[c]['rateMomentum'] = rate_momentum_dates.get(c, str(date.today()))
          time.sleep(1)

          print(f"\n{'='*50}\nSAVING RESULTS\n{'='*50}")
          for curr in CURRENCIES:
              pkg = {
                  'lastUpdate': str(date.today()),
                  'source': 'TradingEconomics â€” v7: +rateMomentum (current_rate - rate_12M_ago); EUR bond10y via /bonds GEUGB10Y:GOV',
                  'data':   all_data[curr],
                  'dates':  all_dates[curr]
              }
              with open(f'extended-data/{curr}.json', 'w') as f:
                  json.dump(pkg, f, indent=2)

              available = [k for k, v in all_data[curr].items() if v is not None]
              missing   = [k for k in ['bond10y','consumerConfidence','businessConfidence',
                                        'capitalFlows','inflationExpectations','rateMomentum']
                           if all_data[curr].get(k) is None]
              status = 'âœ…' if not missing else 'âš ï¸ '
              extras = []
              if curr == 'EUR':
                  extras.append(f"bond10y={all_data['EUR'].get('bond10y','N/A')}% EA agg")
              rm = all_data[curr].get('rateMomentum')
              if rm is not None:
                  extras.append(f"rateMomentum={rm:+.3f}%")
              extra_str = f" [{', '.join(extras)}]" if extras else ''
              print(f"{status} {curr}: {', '.join(available) or 'NO DATA'}{extra_str}")
              if missing:
                  print(f"   Missing: {', '.join(missing)}")

          print("\nâœ… COMPLETE â€” v7")
          EOFPYTHON

      - name: Commit and push
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add extended-data/
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸ“Š Extended data $(date +'%Y-%m-%d') â€” v7 +rateMomentum"
            git pull --rebase origin main || true
            git push
          fi
