name: Update Economic Data - FINAL (TE Multi-source + COT)
on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC
  workflow_dispatch:

jobs:
  update-economic-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 lxml --break-system-packages
      
      - name: Create data directory
        run: mkdir -p economic-data
      
      - name: Scrape economic data
        run: |
          python3 << 'EOFPYTHON'
          import requests
          from bs4 import BeautifulSoup
          import json
          import re
          from datetime import date
          import time
          
          HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          }
          
          CURRENCIES = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']
          
          TRADING_ECONOMICS_URLS = {
              'gdp': 'https://tradingeconomics.com/country-list/gdp?continent=world',
              'gdpGrowth': 'https://tradingeconomics.com/country-list/gdp-growth-rate?continent=world',
              'inflation': 'https://tradingeconomics.com/country-list/inflation-rate?continent=world',
              'unemployment': 'https://tradingeconomics.com/country-list/unemployment-rate?continent=world',
              'debt': 'https://tradingeconomics.com/country-list/government-debt-to-gdp',
              'currentAccount': 'https://tradingeconomics.com/country-list/current-account-to-gdp?continent=world',
              'production': 'https://tradingeconomics.com/country-list/industrial-production?continent=world',
              'tradeBalance': 'https://tradingeconomics.com/country-list/balance-of-trade',
              'retailSales': 'https://tradingeconomics.com/country-list/retail-sales-mom',
              'wageGrowth': 'https://tradingeconomics.com/country-list/wage-growth',
              'manufacturingPMI': 'https://tradingeconomics.com/country-list/manufacturing-pmi'
          }
          
          COUNTRY_URLS = {
              'USD': 'united-states', 'EUR': 'euro-area', 'GBP': 'united-kingdom',
              'JPY': 'japan', 'CAD': 'canada', 'AUD': 'australia',
              'CHF': 'switzerland', 'NZD': 'new-zealand'
          }
          
          INDICATOR_PAGES = {
              'retailSales': 'retail-sales',
              'wageGrowth': 'wage-growth',
              'manufacturingPMI': 'manufacturing-pmi'
          }
          
          COUNTRY_NAMES = {
              'USD': ['United States'], 'EUR': ['Euro Area'], 'GBP': ['United Kingdom'],
              'JPY': ['Japan'], 'CAD': ['Canada'], 'AUD': ['Australia'],
              'CHF': ['Switzerland'], 'NZD': ['New Zealand']
          }
          
          exchange_rates = {}
          
          def fetch_fx():
              global exchange_rates
              try:
                  r = requests.get('https://api.frankfurter.app/latest?from=USD', timeout=10)
                  if r.ok:
                      exchange_rates = r.json().get('rates', {})
                      exchange_rates['USD'] = 1.0
                      return True
              except:
                  pass
              exchange_rates = {'USD': 1.0, 'EUR': 0.84, 'GBP': 0.73, 'JPY': 153.71,
                               'CAD': 1.36, 'AUD': 1.40, 'CHF': 0.77, 'NZD': 1.65}
              return True
          
          def clean_num(text):
              if not text:
                  return None
              text = str(text).strip().replace(',', '').replace('%', '')
              m = re.search(r'(-?\d+\.?\d*)', text)
              return float(m.group(1)) if m else None
          
          def scrape_country_page(country_slug, indicator_page, currency_code):
              url = f'https://tradingeconomics.com/{country_slug}/{indicator_page}'
              try:
                  r = requests.get(url, headers=HEADERS, timeout=20)
                  if not r.ok:
                      return None
                  
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  # Find table with "Actual" column
                  for table in soup.find_all('table'):
                      headers = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                      if 'actual' in headers:
                          idx = headers.index('actual')
                          rows = table.find_all('tr')[1:]
                          if rows:
                              cells = rows[0].find_all('td')
                              if len(cells) > idx:
                                  val = clean_num(cells[idx].get_text(strip=True))
                                  if val is not None:
                                      print(f"    âœ… {currency_code}: {val} (country page)")
                                      return val
                  return None
              except:
                  return None
          
          def parse_tb(cols):
              if len(cols) < 5:
                  return None
              val = clean_num(cols[1].get_text(strip=True))
              unit = cols[4].get_text(strip=True)
              if val is None:
                  return None
              scale = 1000 if 'billion' in unit.lower() else 1
              curr = next((c for c in CURRENCIES if c in unit.upper()), 'USD')
              val_m = val * scale
              if curr != 'USD':
                  fx = exchange_rates.get(curr, 1)
                  val_m = val_m / fx if fx else val_m
              return round(val_m, 2)
          
          def scrape_te(url, indicator):
              print(f"\n{'='*50}")
              print(f"SCRAPING: {indicator.upper()}")
              print(f"{'='*50}")
              
              try:
                  r = requests.get(url, headers=HEADERS, timeout=20)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  data = {}
                  table = soup.find('table', {'class': 'table'})
                  if not table:
                      return data
                  
                  for row in table.find_all('tr')[1:]:
                      cols = row.find_all('td')
                      if len(cols) < 2:
                          continue
                      
                      ctry = cols[0].get_text(strip=True)
                      
                      for code, names in COUNTRY_NAMES.items():
                          if any(n.lower() in ctry.lower() for n in names):
                              val = parse_tb(cols) if indicator == 'tradeBalance' else clean_num(cols[1].get_text(strip=True))
                              if val is not None:
                                  data[code] = round(val, 2)
                                  print(f"  âœ“ {code}: {val}")
                              break
                  
                  return data
              except Exception as e:
                  print(f"  âŒ {e}")
                  return {}
          
          def scrape_fallback(indicator, url):
              data = scrape_te(url, indicator)
              missing = [c for c in CURRENCIES if c not in data]
              
              if missing and indicator in INDICATOR_PAGES:
                  print(f"\n  â†’ Country page fallback for: {', '.join(missing)}")
                  page = INDICATOR_PAGES[indicator]
                  
                  for code in missing:
                      slug = COUNTRY_URLS.get(code)
                      if slug:
                          val = scrape_country_page(slug, page, code)
                          if val is not None:
                              data[code] = val
                          time.sleep(1)
              
              return data
          
          def load_cot():
              import os
              cot = {}
              if not os.path.exists('cot-data'):
                  return {}
              for c in ['EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']:
                  fp = f'cot-data/{c}.json'
                  if os.path.exists(fp):
                      try:
                          with open(fp) as f:
                              cot[c] = json.load(f).get('netPosition')
                      except:
                          pass
              return cot
          
          # MAIN
          print("="*50)
          print("ECONOMIC DATA SCRAPER - FINAL")
          print("="*50)
          
          fetch_fx()
          all_data = {c: {} for c in CURRENCIES}
          
          for ind, url in TRADING_ECONOMICS_URLS.items():
              ind_data = scrape_fallback(ind, url)
              for code, val in ind_data.items():
                  all_data[code][ind] = val
              time.sleep(2)
          
          cot_data = load_cot()
          for code, val in cot_data.items():
              all_data[code]['cotPositioning'] = val
          
          # Save
          today = str(date.today())
          for curr in CURRENCIES:
              pkg = {
                  'lastUpdate': today,
                  'source': 'TradingEconomics + COT',
                  'data': all_data[curr]
              }
              with open(f'economic-data/{curr}.json', 'w') as f:
                  json.dump(pkg, f, indent=2)
              
              missing = [k for k in ['retailSales', 'wageGrowth', 'manufacturingPMI'] 
                        if all_data[curr].get(k) is None]
              print(f"{'âœ…' if not missing else 'âš ï¸ '} {curr}: {'Complete' if not missing else 'Missing ' + ', '.join(missing)}")
          
          print("\nâœ… COMPLETED")
          EOFPYTHON
      
      - name: Commit and push
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add economic-data/
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ðŸ“Š Economic data $(date +'%Y-%m-%d')"
            git pull --rebase origin main || true
            git push
          fi
